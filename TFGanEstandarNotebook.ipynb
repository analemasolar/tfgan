{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvB5xVPpOxBI"
      },
      "source": [
        "FUTURO CAMBIAR A 4 res layer en gen_DOWN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8679lgUbzkTj",
        "outputId": "bd701c06-c3d3-4797-c40b-70137b5cd578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.33.2-py3-none-any.whl (514 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.9/514.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.3.3)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.27.1)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.26.15)\n",
            "Collecting websocket-client<1.4.0,>=0.55.0 (from comet_ml)\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.1/510.1 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.3.4)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.19.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Installing collected packages: everett, wurlitzer, websocket-client, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.5.1\n",
            "    Uninstalling websocket-client-1.5.1:\n",
            "      Successfully uninstalled websocket-client-1.5.1\n",
            "Successfully installed comet_ml-3.33.2 configobj-5.0.8 dulwich-0.21.5 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-1.22.2 simplejson-3.19.1 websocket-client-1.3.3 wurlitzer-3.0.3\n"
          ]
        }
      ],
      "source": [
        "pip install comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4sEY4AlzHgn",
        "outputId": "4b5ab84a-be76-4b92-efa7-1e9a56dc70eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/manuelnevado/awasserstein-loss-esta-vez-bien/a8cc95e23b3e4b22b4bf1dfc8e1e548b\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model\n",
        "experiment = Experiment(\n",
        "  api_key = \"3xZI0xXZ4oGsYBUUQ5FzbVxCC\",\n",
        "  project_name = \"AWasserstein Loss esta vez bien\",\n",
        "  workspace=\"manuelnevado\",\n",
        "  log_code=True,\n",
        "  log_graph=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo8s_1MLzylC"
      },
      "outputs": [],
      "source": [
        "experiment.add_tag(\"Entrenamiento10, viejos a bebes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RQrZ7AEmMQ",
        "outputId": "e29be18f-120a-49ba-b8a4-0cb841d99775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVDwxfffz2Uh"
      },
      "outputs": [],
      "source": [
        "!rm -rf Adults && rm -rf Kids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s69Q9tUgE0H5"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/TFG/UTK_Corto.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9343fb46"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "from time import time\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from math import log2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from math import log2\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE_GEN = 8e-5\n",
        "LEARNING_RATE_DIS = 1e-4\n",
        "LAMBDA_IDENTITY = 0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 1500\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_H = \"genh.pth.tar\"\n",
        "CHECKPOINT_GEN_Z = \"genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = \"critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_Z = \"criticz.pth.tar\"\n",
        "\n",
        "hyper_params = {\n",
        "   \"learning_rate_gen\": LEARNING_RATE_GEN,\n",
        "   \"learning_rate_dis\": LEARNING_RATE_DIS,\n",
        "   \"EPOCH\": NUM_EPOCHS,\n",
        "   \"batch_size\": BATCH_SIZE,\n",
        "   \"lambda_identity\": LAMBDA_IDENTITY\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "893be002"
      },
      "outputs": [],
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    img = img.to(\"cpu\")\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        return npimg\n",
        "    else:\n",
        "        return np.transpose(npimg, (1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5222768",
        "outputId": "87bdc194-0499-47d3-aa8e-5c18896a8b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "class test_class(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Conv2d(3, 3 * 2, kernel_size=3, padding=1)\n",
        "    def forward(self,x):\n",
        "        return self.layer(x)\n",
        "\n",
        "\n",
        "def test():  \n",
        "    model = test_class()\n",
        "    x = torch.randn((2,3,16,16))\n",
        "    print(model(x).shape)\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdcfd9ab",
        "outputId": "2883fd17-5b4f-4f87-cbf9-20e4f50e76b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 100, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "class samplingLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, init_channels=3, final_channels=3):\n",
        "        super().__init__()\n",
        "        self.init_channels = init_channels\n",
        "        self.final_channels = final_channels\n",
        "        self.layer = nn.Conv2d(int(init_channels),int(final_channels),kernel_size=3,padding=1)\n",
        "        self.norm = nn.InstanceNorm2d(final_channels)\n",
        "        self.leaky = nn.ReLU(inplace=True)\n",
        "        return\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.layer(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.leaky(x)\n",
        "        return x\n",
        "\n",
        "def test():\n",
        "    model = samplingLayer(3,100)\n",
        "    x = torch.randn((2,3,32,32))\n",
        "    print(model(x).shape)\n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b15b177e",
        "outputId": "dbf85349-6848-4642-bbdf-5ad5e977dd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 9, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "class downSamplingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, channels=3, channels_out=6):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.channels_out = channels_out\n",
        "        self.layer = nn.Conv2d(int(channels),channels_out,2,stride=2)\n",
        "        #self.norm = nn.InstanceNorm2d(channels_out)\n",
        "        self.leaky = nn.LeakyReLU(inplace=True)\n",
        "        return\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.layer(x)\n",
        "        #x = self.norm(x)\n",
        "        x = self.leaky(x)\n",
        "        return x\n",
        "\n",
        "    \n",
        "def test():\n",
        "    model = downSamplingLayer(3,9)\n",
        "    x = torch.randn((2,3,32,32))\n",
        "    print(model(x).shape)\n",
        "    return\n",
        "\n",
        "test()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ca06795",
        "outputId": "5182cacd-b51a-4410-ed38-b03c878f2990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "class upSamplingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self,channels=6,channels_out=3):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.channels_out = 6\n",
        "        self.layer = nn.ConvTranspose2d(int(channels),int(channels_out),2,stride=2)\n",
        "        self.norm = nn.InstanceNorm2d(channels_out)\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "        return\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.leaky(x)\n",
        "        return x\n",
        "    \n",
        "def test():\n",
        "    model = upSamplingLayer(channels=10)\n",
        "    x = torch.randn((2,10,8,8))\n",
        "    print(model(x).shape)\n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39980b57",
        "outputId": "5b2a644d-c128-4227-bd56-73cb6befd65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 16, 16])\n"
          ]
        }
      ],
      "source": [
        "class residualLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, channels = 3):\n",
        "        self.channels = channels\n",
        "        super().__init__()\n",
        "        layer1 = nn.Sequential(\n",
        "            nn.Conv2d(self.channels, self.channels, kernel_size=3,padding=1),\n",
        "            nn.InstanceNorm2d(self.channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        layer2 = nn.Sequential(\n",
        "            nn.Conv2d(self.channels, self.channels, kernel_size=3,padding=1),\n",
        "            nn.InstanceNorm2d(self.channels),\n",
        "            nn.Identity()\n",
        "        ) \n",
        "        \n",
        "        self.bifurcacion = nn.Sequential(\n",
        "            layer1,\n",
        "            layer2\n",
        "        )\n",
        "        return\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = x + self.bifurcacion(x)\n",
        "      return x\n",
        "    \n",
        "def test():\n",
        "    model = residualLayer()\n",
        "    x = torch.randn((2,3,16,16))\n",
        "    print(model(x).shape)\n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71820500",
        "outputId": "c7945ff7-4105-46f9-cde0-4af873a68045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: DownSampler(\n",
            "  (model): Sequential(\n",
            "    (0): samplingLayer(\n",
            "      (layer): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 3, 8, 8])\n",
            "model: DownSampler(\n",
            "  (model): Sequential(\n",
            "    (0): downSamplingLayer(\n",
            "      (layer): Conv2d(1, 1, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (leaky): LeakyReLU(negative_slope=0.01, inplace=True)\n",
            "    )\n",
            "    (1): samplingLayer(\n",
            "      (layer): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([5, 1, 16, 16])\n",
            "torch.Size([5, 3, 8, 8])\n"
          ]
        }
      ],
      "source": [
        "class DownSampler(nn.Module):\n",
        "    \n",
        "    def __init__(self, img_resolution, channels=3, frontier=8):\n",
        "        #frontier parameter must be the same between UpSampler and DownSampler\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.frontier = frontier\n",
        "        self.img_resolution = img_resolution\n",
        "        \n",
        "        \n",
        "        self.model = nn.Sequential()\n",
        "        if self.img_resolution == self.frontier:\n",
        "            self.model.append(samplingLayer(channels))\n",
        "        else:\n",
        "            while img_resolution > self.frontier:\n",
        "                self.model.append(downSamplingLayer(channels,channels))\n",
        "                img_resolution = img_resolution/2\n",
        "        return\n",
        "    \n",
        "    def crece(self):\n",
        "        #self.model.insert(0,downSamplingLayer(self.channels))\n",
        "        model_new = nn.Sequential()\n",
        "        model_new.append(downSamplingLayer(self.channels,self.channels))\n",
        "        for layer in self.model:\n",
        "            model_new.append(layer)\n",
        "        self.model = model_new\n",
        "        return\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "    \n",
        "def test():\n",
        "    img = 8\n",
        "    model = DownSampler(img,channels=1)\n",
        "    \n",
        "    for _ in range(2):\n",
        "        x = torch.randn((5,1,img,img))\n",
        "        print(f\"model: {model}\")\n",
        "        print(x.shape)\n",
        "        print(model(x).shape)\n",
        "        img *=2\n",
        "        model.crece()\n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf2a9c8",
        "outputId": "c0bf8b99-1685-4f17-87ef-ef47418ee7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 8, 8])\n",
            "torch.Size([5, 3, 8, 8])\n",
            "torch.Size([5, 3, 8, 8])\n"
          ]
        }
      ],
      "source": [
        "class ResidualSampler(nn.Module):\n",
        "    \n",
        "    def __init__(self, channels=3, n_residuals = 2):\n",
        "        super().__init__()\n",
        "        self.channels =channels\n",
        "        self.n_residuals = n_residuals\n",
        "        self.model = nn.Sequential()\n",
        "        for _ in range(self.n_residuals):\n",
        "            self.model.append(residualLayer(channels))\n",
        "        return\n",
        "    \n",
        "    def crece(self, n=1):\n",
        "        for _ in range(n):\n",
        "            self.model.append(residualLayer(self.channels))\n",
        "        return\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "def test():\n",
        "    img = 8\n",
        "    model = ResidualSampler()\n",
        "    for _ in range(3):\n",
        "        x = torch.randn((5,3,img,img))\n",
        "        print(model(x).shape)\n",
        "        model.crece()\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8fae412",
        "outputId": "b97bf5aa-e18f-4e62-ff24-a5d08638358b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector size: torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 1, 8, 8])\n",
            "vector size: torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 1, 16, 16])\n",
            "vector size: torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 1, 32, 32])\n",
            "vector size: torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 1, 64, 64])\n",
            "vector size: torch.Size([5, 1, 8, 8])\n",
            "torch.Size([5, 1, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "class UpSampler(nn.Module):\n",
        "    \n",
        "    def __init__(self,img_resolution, channels=3, frontier=8):\n",
        "        #frontier parameter must be the same between UpSampler and DownSampler\n",
        "        super().__init__()\n",
        "        self.frontier = frontier\n",
        "        self.img_resolution = img_resolution\n",
        "        self.channels = channels\n",
        "        self.model = nn.Sequential() \n",
        "        if self.img_resolution == self.frontier:\n",
        "            self.model.append(samplingLayer(channels,final_channels=channels))\n",
        "        else:\n",
        "            while img_resolution > self.frontier:\n",
        "                self.model.append(upSamplingLayer(channels,channels))\n",
        "                img_resolution = img_resolution/2\n",
        "        return\n",
        "    \n",
        "    def crece(self):\n",
        "        self.model.append(upSamplingLayer(self.channels,self.channels))\n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.model(x)\n",
        "\n",
        "def test():\n",
        "    img = 8\n",
        "    model = UpSampler(img,channels=1)\n",
        "    \n",
        "    for _ in range(5):\n",
        "        x = torch.randn((5,1,8,8))\n",
        "        print(f\"vector size: {x.shape}\")\n",
        "        print(model(x).shape)\n",
        "        img *=2\n",
        "        model.crece()\n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCzz1DUYSYGa",
        "outputId": "e23eb052-6396-479e-916d-cd02d6403d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generador_down(\n",
            "  (model_sequential): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (10): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ResidualBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (13): ResidualBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (14): ResidualBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (15): Identity()\n",
            "    (16): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Identity()\n",
            "    (19): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Identity()\n",
            "    (22): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): ReLU(inplace=True)\n",
            "    (24): Identity()\n",
            "    (25): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Identity()\n",
            "    (28): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): Tanh()\n",
            "  )\n",
            ")\n",
            "shape returned by model: torch.Size([2, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "\n",
        "class Generador_down(nn.Module):\n",
        "    \n",
        "    def __init__(self, img_resolution, frontier, num_residuals=3, init_channels=1, frontier_channels=100, paso_de_canal=10, rabit_hole=5):\n",
        "        super().__init__()\n",
        "        self.img_resolution = img_resolution\n",
        "        self.frontier = frontier\n",
        "        self.growing_step = int(log2(img_resolution)-log2(frontier))\n",
        "        self.init_channels = init_channels\n",
        "        self.final_channels = 2**self.growing_step*self.init_channels\n",
        "        self.frontier_channels = frontier_channels\n",
        "        self.paso_de_canal = paso_de_canal\n",
        "\n",
        "        #Inicial\n",
        "        out_features = 64\n",
        "        self.model = [\n",
        "            #nn.ReflectionPad2d(init_channels),\n",
        "            nn.Conv2d(init_channels, out_features, kernel_size=3,stride=1,padding=1),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        in_features = out_features\n",
        "        \n",
        "        current_size = img_resolution\n",
        "        #DOWNSAMPLING\n",
        "        while current_size>frontier:\n",
        "          out_features *= 2\n",
        "          self.model += [\n",
        "              nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), # --> width/2 ,heigth/2\n",
        "              nn.InstanceNorm2d(out_features),\n",
        "              nn.ReLU(inplace=True)\n",
        "          ]\n",
        "          in_features = out_features\n",
        "          current_size = int(current_size/2)\n",
        "          #print(f\"current_size: {current_size}\")\n",
        "        \n",
        "        #RESIDUAL\n",
        "        for _ in range(num_residuals):\n",
        "            self.model += [ResidualBlock(out_features)]\n",
        "\n",
        "        #UPSAMPLING\n",
        "        for _ in range(rabit_hole):\n",
        "            out_features //= 2\n",
        "            self.model += [\n",
        "                nn.Upsample(scale_factor=2) if current_size < frontier else nn.Identity(), # --> width*2, heigh*2\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "            current_size *= 2\n",
        "        \n",
        "        # Output Layer\n",
        "        self.model += [\n",
        "                  #nn.ReflectionPad2d(init_channels),\n",
        "                  nn.Conv2d(out_features, init_channels, 3,stride=1,padding=1),\n",
        "                  nn.Tanh()\n",
        "                 ]\n",
        "        \n",
        "        #UNPACK\n",
        "        self.model_sequential = nn.Sequential(*self.model)\n",
        "        \n",
        "\n",
        "        return\n",
        "    \n",
        "    def crece(self):\n",
        "        if self.growing_step > 0:\n",
        "            \n",
        "            #Crece Down\n",
        "            self.growing_step -= 1\n",
        "            new_channels = 2**self.growing_step*self.init_channels\n",
        "            \n",
        "            #La primera\n",
        "            self.initial = downSamplingLayer(self.init_channels,new_channels)\n",
        "            \n",
        "            #La nueva bajada\n",
        "            new_down = downSamplingLayer(new_channels,new_channels*2)\n",
        "            self.down_layers.insert(0,new_down)\n",
        "            \n",
        "            #La nueva subida\n",
        "            new_up = samplingLayer(new_channels*2,new_channels)\n",
        "            self.up_layers.append(new_up)\n",
        "            \n",
        "            #La ultima capa\n",
        "            self.last_layer = samplingLayer(new_channels,self.init_channels)\n",
        "            return True\n",
        "            \n",
        "        else:\n",
        "            print(\"La red no puede crecer mas\")\n",
        "        \n",
        "        return False\n",
        "    \n",
        "    def crece_res(self, times=1):\n",
        "        \n",
        "        for _ in range(times):\n",
        "            self.res_layers.append(residualLayer(self.final_channels))\n",
        "    \n",
        "    def forward(self,x):\n",
        "      #print(f\"init shape{x.shape}\")\n",
        "      for layer in self.model:\n",
        "        x = layer(x)\n",
        "        #print(f\"for layer:{layer} shape returned is: {x.shape}\")\n",
        "      return x\n",
        "      #return self.model_sequential(x)\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((2,3,512,512)).to(\"cuda\")\n",
        "    model = Generador_down(512,64,init_channels=3, paso_de_canal=10).to(\"cuda\")\n",
        "    print(model)\n",
        "    print(f\"shape returned by model: {model(x).shape}\")    \n",
        "    return\n",
        "\n",
        "test()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RURU3oWNO6nx",
        "outputId": "10e92373-48ac-4b6b-fff7-2b9aa197ed32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generador_res(\n",
            "  (res_up): Sequential(\n",
            "    (0): samplingLayer(\n",
            "      (layer): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(6, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): samplingLayer(\n",
            "      (layer): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(12, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): samplingLayer(\n",
            "      (layer): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): samplingLayer(\n",
            "      (layer): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): samplingLayer(\n",
            "      (layer): Conv2d(48, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(58, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): samplingLayer(\n",
            "      (layer): Conv2d(58, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(68, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): samplingLayer(\n",
            "      (layer): Conv2d(68, 78, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(78, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): samplingLayer(\n",
            "      (layer): Conv2d(78, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(88, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): samplingLayer(\n",
            "      (layer): Conv2d(88, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(98, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): samplingLayer(\n",
            "      (layer): Conv2d(98, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (res_block): Sequential(\n",
            "    (0): residualLayer(\n",
            "      (bifurcacion): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): residualLayer(\n",
            "      (bifurcacion): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): residualLayer(\n",
            "      (bifurcacion): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): residualLayer(\n",
            "      (bifurcacion): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): residualLayer(\n",
            "      (bifurcacion): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): InstanceNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (res_down): Sequential(\n",
            "    (0): samplingLayer(\n",
            "      (layer): Conv2d(100, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(90, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): samplingLayer(\n",
            "      (layer): Conv2d(90, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): samplingLayer(\n",
            "      (layer): Conv2d(80, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(70, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): samplingLayer(\n",
            "      (layer): Conv2d(70, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(60, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): samplingLayer(\n",
            "      (layer): Conv2d(60, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(50, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): samplingLayer(\n",
            "      (layer): Conv2d(50, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): samplingLayer(\n",
            "      (layer): Conv2d(40, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(30, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): samplingLayer(\n",
            "      (layer): Conv2d(30, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(20, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): samplingLayer(\n",
            "      (layer): Conv2d(20, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): samplingLayer(\n",
            "      (layer): Conv2d(10, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (leaky): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "shape returned by model: torch.Size([5, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "class Generador_res(nn.Module):\n",
        "    \n",
        "    def __init__(self, img_resolution, frontier, num_de_paso=2, init_channels=1, frontier_channels=100, paso_de_canal=10, num_residuals=5):\n",
        "        super().__init__()\n",
        "        self.img_resolution = img_resolution\n",
        "        self.frontier = frontier\n",
        "        self.growing_step = int(log2(img_resolution)-log2(frontier))\n",
        "        self.init_channels = init_channels\n",
        "        self.final_channels = 2**self.growing_step*self.init_channels\n",
        "        self.frontier_channels = frontier_channels\n",
        "        self.paso_de_canal = paso_de_canal\n",
        "  \n",
        "        #construccion del modelo Res\n",
        "        #Subida de canales\n",
        "        self.res_up = nn.Sequential()\n",
        "        current_channels = self.init_channels\n",
        "        for _ in range(num_de_paso):\n",
        "          self.res_up.append(samplingLayer(current_channels, current_channels*2))\n",
        "          current_channels *= 2\n",
        "        \n",
        "        while current_channels+paso_de_canal < frontier_channels:\n",
        "          self.res_up.append(samplingLayer(current_channels,current_channels+paso_de_canal))\n",
        "          current_channels+=paso_de_canal\n",
        "        self.res_up.append(samplingLayer(current_channels,frontier_channels))\n",
        "        \n",
        "        #residuales\n",
        "        self.res_block = nn.Sequential()\n",
        "        for _ in range(num_residuals):\n",
        "          self.res_block.append(residualLayer(frontier_channels))\n",
        "        \n",
        "        #para arriba\n",
        "        self.res_down = nn.Sequential()\n",
        "        current_channels = frontier_channels\n",
        "        while current_channels-paso_de_canal > init_channels:\n",
        "          self.res_down.append(samplingLayer(current_channels, current_channels-paso_de_canal))\n",
        "          current_channels = current_channels-paso_de_canal\n",
        "        self.res_down.append(samplingLayer(current_channels,init_channels))\n",
        "\n",
        "        return\n",
        "    \n",
        "    def crece(self):\n",
        "        if self.growing_step > 0:\n",
        "            print(\"Growing deprecated\")\n",
        "            return True\n",
        "            \n",
        "        else:\n",
        "            print(\"La red no puede crecer mas\")\n",
        "        \n",
        "        return False\n",
        "    \n",
        "    def crece_res(self, times=1):\n",
        "        \n",
        "        \"\"\"for _ in range(times):\n",
        "            self.res_layers.append(residualLayer(self.final_channels))\n",
        "        \"\"\"\n",
        "        print(\"Crece res deprecated\")\n",
        "        return\n",
        "\n",
        "    def forward(self,x):\n",
        "        \n",
        "        #print(f\"shape initial_out: {x.shape}\")\n",
        "        for layer in self.res_up:\n",
        "            x = layer(x)\n",
        "            #print(f\"shape down_out: {x.shape}\")\n",
        "        \n",
        "        #for layer in self.res_block:\n",
        "        #    x = layer(x)\n",
        "            #print(f\"shape res_out: {x.shape}\")\n",
        "        \n",
        "        for layer in self.res_down:\n",
        "            x = layer(x)\n",
        "            #print(f\"shape up_out: {x.shape}\")\n",
        "                    \n",
        "        return x\n",
        "\n",
        "def test():\n",
        "    x = torch.randn((5,3,64,64)).to(\"cuda\")\n",
        "    model = Generador_res(64,64, num_de_paso=4, init_channels=3).to(\"cuda\")\n",
        "    print(model)\n",
        "    print(f\"shape returned by model: {model(x).shape}\")\n",
        "    \n",
        "    return\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-aYp1qFLsP4",
        "outputId": "286487eb-980d-4300-f1b1-18b7967897e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img_size: 64\n",
            "tensor([[[[-0.1005, -0.0104,  0.8960,  0.3281, -0.0969, -0.2686],\n",
            "          [ 0.0905,  0.4450,  0.3765,  0.5920, -0.1397,  0.0278],\n",
            "          [ 0.2782,  0.3142,  0.8912,  0.6288,  0.5065, -0.3603],\n",
            "          [ 0.1740, -0.4275,  0.2641,  0.8438,  0.0948, -0.6652],\n",
            "          [ 0.2197, -0.5648,  0.2173, -0.2449,  0.4499, -0.1673],\n",
            "          [ 0.8336,  0.1766, -0.1296,  0.0607, -0.2620,  0.3027]]]],\n",
            "       device='cuda:0', grad_fn=<ConvolutionBackward0>)\n",
            "tensor(0.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "torch.Size([1, 1, 6, 6])\n",
            "Discriminador(\n",
            "  (layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Discriminador(nn.Module):\n",
        "    def __init__(self, img_size,channels =3, frontier=4, paso_de_canal=2):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.img_size = img_size\n",
        "        self.frontier = frontier\n",
        "        self.paso_de_canal = paso_de_canal\n",
        "        nc = channels\n",
        "        ndf = 64\n",
        "        self.layers = nn.Sequential(\n",
        "            # input is (nc) x 128 x 128\n",
        "            nn.Conv2d(nc,ndf,4,2,1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 64 x 64\n",
        "            nn.Conv2d(ndf,ndf*2,4,2,1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 32 x 32\n",
        "            nn.Conv2d(ndf*2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.InstanceNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            #ResidualBlock(ndf*4),\n",
        "            #ResidualBlock(ndf*4),\n",
        "\n",
        "            # state size. (ndf*4) x 16 x 16\n",
        "            nn.Conv2d(ndf*4,ndf*8,4,1,1),\n",
        "            nn.InstanceNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 15 x 15\n",
        "            nn.Conv2d(ndf*8,1,4,1,1)\n",
        "            # state size. 1 x 14 x 14\n",
        "        )\n",
        "        \n",
        "        \"\"\"#Las capas de crecimiento\n",
        "        output_features = 32\n",
        "        input_features = channels\n",
        "        i = 0\n",
        "        while img_size > self.frontier:\n",
        "            self.layers.append(nn.Conv2d(\n",
        "                input_features,output_features,\n",
        "                kernel_size=3,padding=1,stride=1, padding_mode='reflect'))\n",
        "            if i>0:\n",
        "              self.layers.append(nn.InstanceNorm2d(output_features))\n",
        "            self.layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            img_size = img_size/2\n",
        "            input_features = output_features\n",
        "            output_features *= 2\n",
        "\n",
        "        \n",
        "        # La ultima capa\n",
        "        self.layers.append(nn.Conv2d(input_features,1,\n",
        "                                        kernel_size=4,\n",
        "                                        stride=1,\n",
        "                                        padding=1,\n",
        "                                        padding_mode=\"reflect\",))\"\"\"\n",
        "        \n",
        "        return\n",
        "    \n",
        "    def crece(self):\n",
        "        print(\"Growing Deprecated\")\n",
        "        '''self.img_size *= 2\n",
        "        self.layers.insert(0,nn.Conv2d(3,3,1,stride=2))'''\n",
        "        return\n",
        "    \n",
        "    def forward(self, x):\n",
        "      #print(f\"input shape: {x.shape}\")\n",
        "      return self.layers(x)\n",
        "\n",
        "def test(i):\n",
        "    img_size = i\n",
        "    model = Discriminador(img_size, frontier=2,channels=3).to(DEVICE)\n",
        "    \n",
        "    print(f\"img_size: {img_size}\")\n",
        "    x = torch.randn((1,3,img_size,img_size)).to(DEVICE)\n",
        "\n",
        "    print(model(x))\n",
        "    print(torch.mean(model(x)))\n",
        "    print(model(x).shape)\n",
        "    print(model)\n",
        "    return\n",
        "\n",
        "test(64)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02f567f7"
      },
      "outputs": [],
      "source": [
        "transforms1 = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=32, height=32),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5,], std=[0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")\n",
        "\n",
        "transforms2 = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=16, height=16),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[ 0.5], std=[0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a588b674",
        "outputId": "80cfea6b-50be-429b-b23b-ce7633d9c488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32])\n",
            "torch.Size([1, 16, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class TFGAN_Dataset(Dataset):\n",
        "    \n",
        "    #Por estandar\n",
        "    #  root_A = Adultos\n",
        "    #  root_b = Kids\n",
        " \n",
        "    def __init__(self, root_A, root_B, transform1=None, transform2=None, gray_scale=True):    \n",
        "        self.root_A = root_A\n",
        "        self.root_B = root_B\n",
        "        self.transform1 = transform1\n",
        "        self.transform2 = transform2\n",
        "        self.gray_scale = gray_scale\n",
        "        \n",
        "        self.root_A_images = os.listdir(root_A)\n",
        "        self.root_B_images = os.listdir(root_B)\n",
        "        self.length_dataset = max(len(self.root_A_images), len(self.root_B_images))\n",
        "        self.root_A_len = len(self.root_A_images)\n",
        "        self.root_B_len = len(self.root_B_images)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        A_image = self.root_A_images[index % self.root_A_len]\n",
        "        B_image = self.root_B_images[index % self.root_B_len]\n",
        "\n",
        "        A_path = os.path.join(self.root_A, A_image)\n",
        "        B_path = os.path.join(self.root_B, B_image)\n",
        "\n",
        "        A_image = np.array(Image.open(A_path).convert(\"L\" if self.gray_scale else \"RGB\"))\n",
        "        B_image = np.array(Image.open(B_path).convert(\"L\" if self.gray_scale else \"RGB\"))\n",
        "        \n",
        "        A_image1 = A_image\n",
        "        A_image2 = A_image\n",
        "        \n",
        "        B_image1 = B_image\n",
        "        B_image2 = B_image\n",
        "        \n",
        "        if self.transform1:\n",
        "            augmentations1 = self.transform1(image=A_image, image0=B_image)\n",
        "            augmentations2 = self.transform2(image=A_image, image0=B_image)\n",
        "\n",
        "            A_image1 = augmentations1[\"image\"]\n",
        "            A_image2 = augmentations2[\"image\"]\n",
        "            B_image1 = augmentations1[\"image0\"]\n",
        "            B_image2 = augmentations2[\"image0\"]\n",
        "            \n",
        "\n",
        "        return A_image1, B_image1, A_image2, B_image2\n",
        "\n",
        "def test():\n",
        "    train_path = \".\"\n",
        "    Adults_train = os.path.join(train_path, 'Adults')\n",
        "    Kids_train = os.path.join(train_path, 'Kids')\n",
        "    \n",
        "    data = TFGAN_Dataset(Adults_train, Kids_train, transform1=transforms1, transform2=transforms2, gray_scale=True)\n",
        "    \n",
        "    model = ResidualSampler(channels=1)\n",
        "    print(model(data[0][0]).shape)\n",
        "    print(data[0][2].shape)\n",
        "    return True\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cf9aa59"
      },
      "outputs": [],
      "source": [
        "def loss_gan(fake,real):\n",
        "    MSE = nn.L1Loss()\n",
        "    return MSE(fake,real)\n",
        "\n",
        "def loss_dis(fake, real):\n",
        "    MSE = nn.MSELoss()\n",
        "    return MSE(real,fake)\n",
        "\n",
        "def loss_id(in1, out1, in2, out2):\n",
        "    return torch.abs(in1-out1).mean() + torch.abs(in2-out2).mean()\n",
        "\n",
        "def dis_loss_wasserstein_gan(fake_img, real_img):\n",
        "    return torch.mean(real_img)-torch.mean(fake_img)\n",
        "\n",
        "def gen_loss_wasserstein_gan(fake_img): #fake_img es gen(input)\n",
        "    return torch.mean(fake_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af61b1f2"
      },
      "outputs": [],
      "source": [
        "### Checkpoints\n",
        "import random, torch, os, numpy as np\n",
        "import copy\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    #print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8ec6fd2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def train_individual(\n",
        "    writer, epoch, i,\n",
        "    loader, l1, mse, \n",
        "    disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_down, opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "    disc_Adults_res, disc_Kids_res, res_sampler, opt_disc_res, opt_gen_res, d_res_scaler, g_res_scaler,\n",
        "    disc_Adult_up, disc_Kids_up, up_sampler, opt_disc_up, opt_gen_up, d_up_scaler, g_up_scaler   \n",
        "):\n",
        "    \n",
        "    adults_reals = 0\n",
        "    adults_fakes = 0\n",
        "    \n",
        "    loop = tqdm(loader, leave=True)\n",
        "    \n",
        "    for idx, (adult, kid, adult_frontier, kid_frontier) in enumerate(loop):\n",
        "        #Mandamos las cosas a su sitio\n",
        "        adult = adult.to(DEVICE)\n",
        "        adult_frontier = adult_frontier.to(DEVICE)        \n",
        "        kid = kid.to(DEVICE)\n",
        "        kid_frontier = kid_frontier.to(DEVICE)\n",
        "        \n",
        "        #Entrenamos los discriminadores\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_adult_down = down_sampler(kid)\n",
        "            fake_adult_res = res_sampler(kid_frontier)\n",
        "            fake_adult_up = up_sampler(kid_frontier)\n",
        "            \n",
        "            #DOWN\n",
        "            disc_adult_down_real = disc_Kids_down(adult_frontier)\n",
        "            disc_adult_down_fake = disc_Kids_down(fake_adult_down.detach())\n",
        "            \n",
        "            disc_adult_down_real_loss = mse(\n",
        "                disc_adult_down_real, \n",
        "                torch.ones_like(disc_adult_down_real)\n",
        "            )\n",
        "            disc_adult_down_fake_loss = mse(\n",
        "                disc_adult_down_fake,\n",
        "                torch.zeros_like(disc_adult_down_fake)\n",
        "            )\n",
        "            disc_adult_down_loss = disc_adult_down_real_loss + disc_adult_down_fake_loss\n",
        "            writer.add_scalar(\"Down_dis_loss/train\", disc_adult_down_loss,  i)\n",
        "            \n",
        "            #RES\n",
        "            disc_adult_res_real = disc_Kids_res(adult_frontier)\n",
        "            disc_adult_res_fake = disc_Kids_res(fake_adult_res.detach())\n",
        "            \n",
        "            adults_reals += disc_adult_res_real.mean().item()\n",
        "            adults_fakes += disc_adult_res_fake.mean().item()\n",
        "            \n",
        "            disc_adult_res_real_loss = mse(\n",
        "                disc_adult_res_real, \n",
        "                torch.ones_like(disc_adult_res_real)\n",
        "            )\n",
        "            disc_adult_res_fake_loss = mse(\n",
        "                disc_adult_res_fake,\n",
        "                torch.zeros_like(disc_adult_res_fake)\n",
        "            )\n",
        "            disc_adult_res_loss = disc_adult_res_real_loss + disc_adult_res_fake_loss\n",
        "            writer.add_scalar(\"Res_dis_loss/train\", disc_adult_res_loss,  i)\n",
        "            \n",
        "            #UP\n",
        "            disc_adult_up_real = disc_Kids_up(adult)\n",
        "            disc_adult_up_fake = disc_Kids_up(fake_adult_up.detach())\n",
        "            \n",
        "            adults_reals += disc_adult_up_real.mean().item()\n",
        "            adults_fakes += disc_adult_up_fake.mean().item()\n",
        "            \n",
        "            disc_adult_up_real_loss = mse(\n",
        "                disc_adult_up_real, \n",
        "                torch.ones_like(disc_adult_up_real)\n",
        "            )\n",
        "            disc_adult_up_fake_loss = mse(\n",
        "                disc_adult_up_fake,\n",
        "                torch.zeros_like(disc_adult_up_fake)\n",
        "            )\n",
        "            disc_adult_up_loss = disc_adult_up_real_loss + disc_adult_up_fake_loss\n",
        "            writer.add_scalar(\"Up_dis_loss/train\", disc_adult_up_loss, i)\n",
        "            \n",
        "            #Como no hay consistencia de ciclo no neecesitamos entrenar los segundos generadores \n",
        "            #Lo juntamos todo, no nos sirve para entreno solo para ver como va la cosa\n",
        "            D_loss = (disc_adult_down_loss + disc_adult_res_loss + disc_adult_up_loss)/3\n",
        "            \n",
        "            adults_reals += disc_adult_up_real.mean().item()\n",
        "            adults_fakes += disc_adult_up_fake.mean().item()\n",
        "        \n",
        "        \n",
        "        #APLICAMOS LOS CAMBIOS DEL ENTRENO:\n",
        "        \n",
        "        #DOWN\n",
        "        opt_disc_down.zero_grad()\n",
        "        d_down_scaler.scale(disc_adult_down_loss).backward()\n",
        "        d_down_scaler.step(opt_disc_down)\n",
        "        d_down_scaler.update()\n",
        "        #RES\n",
        "        opt_disc_res.zero_grad()\n",
        "        d_res_scaler.scale(disc_adult_res_loss).backward()\n",
        "        d_res_scaler.step(opt_disc_res)\n",
        "        d_res_scaler.update()\n",
        "        #UP\n",
        "        opt_disc_up.zero_grad()\n",
        "        d_up_scaler.scale(disc_adult_up_loss).backward()\n",
        "        d_up_scaler.step(opt_disc_up)\n",
        "        d_up_scaler.update()\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Ahora entrenamos los generadores con lo que hemos sacado de los discriminadores\n",
        "        with torch.cuda.amp.autocast():\n",
        "            #adversarial loss para los generadores\n",
        "            dis_adult_down_fake = disc_Adults_down(fake_adult_down)\n",
        "            loss_gen_down_adult = mse(dis_adult_down_fake, torch.ones_like(dis_adult_down_fake))\n",
        "            writer.add_scalar(\"Down_gen_loss/train\", loss_gen_down_adult, i)\n",
        "            \n",
        "            dis_adult_res_fake = disc_Adults_res(fake_adult_res)\n",
        "            loss_gen_res_adult = mse(dis_adult_res_fake, torch.ones_like(dis_adult_res_fake))\n",
        "            writer.add_scalar(\"Res_gen_loss/train\", loss_gen_res_adult, i)\n",
        "            \n",
        "            dis_adult_up_fake = disc_Adult_up(fake_adult_up)\n",
        "            loss_gen_up_adult = mse(dis_adult_up_fake, torch.ones_like(dis_adult_up_fake))\n",
        "            writer.add_scalar(\"Up_gen_loss/train\", loss_gen_up_adult, i)\n",
        "            \n",
        "            #identity loss (para no alterar las caracteristicas principales)\n",
        "            identity_adult_down = down_sampler(adult)\n",
        "            identity_adult_down_loss = l1(adult_frontier, identity_adult_down)\n",
        "            writer.add_scalar(\"Identity_down_loss/train\", identity_adult_down_loss, i)\n",
        "            \n",
        "            identity_adult_res = res_sampler(adult_frontier)\n",
        "            identity_adult_res_loss = l1(adult_frontier, identity_adult_res)\n",
        "            \n",
        "            identity_adult_up = up_sampler(adult_frontier)\n",
        "            identity_adult_up_loss = l1(adult, identity_adult_up)\n",
        "            \n",
        "            #Se suma todo\n",
        "            g_down_loss = (loss_gen_down_adult + identity_adult_down_loss*LAMBDA_IDENTITY)\n",
        "            g_res_loss = (loss_gen_res_adult + identity_adult_res_loss*LAMBDA_IDENTITY)\n",
        "            g_up_loss = (loss_gen_up_adult + identity_adult_up_loss*LAMBDA_IDENTITY)\n",
        "            \n",
        "        #APLICAMOS LOS CAMBIOS DEL ENTRENO:\n",
        "        \n",
        "        #DOWN\n",
        "        opt_gen_down.zero_grad()\n",
        "        g_down_scaler.scale(g_down_loss).backward()\n",
        "        g_down_scaler.step(opt_gen_down)\n",
        "        g_down_scaler.update()\n",
        "        \n",
        "        #RES\n",
        "        opt_gen_res.zero_grad()\n",
        "        g_res_scaler.scale(g_res_loss).backward()\n",
        "        g_res_scaler.step(opt_gen_res)\n",
        "        g_res_scaler.update()\n",
        "        \n",
        "        #UP\n",
        "        opt_gen_up.zero_grad()\n",
        "        g_up_scaler.scale(g_up_loss).backward()\n",
        "        g_up_scaler.step(opt_gen_up)\n",
        "        g_up_scaler.update()\n",
        "        \n",
        "        if idx%500==0:\n",
        "            save_image(fake_adult_down*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/adult_down{idx}.png\")\n",
        "            save_image(fake_adult_res*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/adult_res{idx}.png\")\n",
        "            save_image(fake_adult_up*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/adult_up{idx}.png\")\n",
        "            save_image(up_sampler(res_sampler(down_sampler(kid)))*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/fake_test{idx}.png\")\n",
        "            save_checkpoint(down_sampler, opt_gen_down, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/gen_down.pth.tar\")\n",
        "            save_checkpoint(disc_Kids_down, opt_disc_down, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/disc_Kids_down.pth.tar\")\n",
        "            save_checkpoint(disc_Adults_down, opt_disc_down, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/disc_Adults_down.pth.tar\")\n",
        "            save_checkpoint(res_sampler, opt_gen_res, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/gen_res.pth.tar\")\n",
        "            save_checkpoint(disc_Kids_res, opt_disc_res, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/disc_Kids_res.pth.tar\")\n",
        "            save_checkpoint(disc_Adults_res, opt_disc_res, filename=\"/content/drive/MyDrive/TFG/Images/Entrenamiento3/Modelos/disc_Adults_res.pth.tar\")\n",
        "\n",
        "            \n",
        "            img_grid = torchvision.utils.make_grid(adult)\n",
        "            #matplotlib_imshow(img_grid, one_channel=True)\n",
        "            img_grid_kid = torchvision.utils.make_grid(fake_adult_down)\n",
        "            writer.add_image('input', torchvision.utils.make_grid(kid_frontier), i)\n",
        "            writer.add_image('output', torchvision.utils.make_grid(fake_adult_res), i)\n",
        "\n",
        "            writer.add_image('input_down', torchvision.utils.make_grid(kid), i)\n",
        "            writer.add_image('output_down', torchvision.utils.make_grid(fake_adult_down), i)\n",
        "\n",
        "            writer.add_image('target', torchvision.utils.make_grid(adult_frontier), i)\n",
        "            #writer.add_image('fake_adults_down', torchvision.utils.make_grid(fake_adult_down),idx)\n",
        "            #writer.add_image('fake_adults_res', torchvision.utils.make_grid(fake_adult_res), idx)\n",
        "            writer.add_graph(down_sampler,kid)\n",
        "            writer.add_graph(disc_Adults_down,kid)\n",
        "            writer.add_graph(res_sampler,kid_frontier)\n",
        "        \n",
        "        loop.set_postfix(adults_reals = adults_reals / (idx+1), adults_fakes = adults_fakes / (idx+1))\n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFNxzJBwx_dV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def train_individual_down(\n",
        "    writer, epoch, i,\n",
        "    loader, l1, mse, \n",
        "    disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_Adults_down, opt_disc_Kids_down, opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "):\n",
        "    \n",
        "    adults_reals = 0\n",
        "    adults_fakes = 0\n",
        "    \n",
        "    loop = tqdm(loader, leave=True)\n",
        "    \n",
        "    for idx, (adult, kid, adult_frontier, kid_frontier) in enumerate(loop):\n",
        "        i+=1\n",
        "        #Mandamos las cosas a su sitio\n",
        "        adult = adult.to(DEVICE)\n",
        "        adult_frontier = adult_frontier.to(DEVICE)        \n",
        "        kid = kid.to(DEVICE)\n",
        "        kid_frontier = kid_frontier.to(DEVICE)\n",
        "        \n",
        "        #Entrenamos los discriminadores\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_adult_down = down_sampler(kid)\n",
        "            \n",
        "            #DOWN\n",
        "            disc_adult_down_real = disc_Adults_down(adult_frontier)\n",
        "            disc_adult_down_fake = disc_Adults_down(fake_adult_down.detach())\n",
        "            \n",
        "            \"\"\"disc_adult_down_real_loss = mse(\n",
        "                disc_adult_down_real, \n",
        "                torch.ones_like(disc_adult_down_real)\n",
        "            )\n",
        "            disc_adult_down_fake_loss = mse(\n",
        "                disc_adult_down_fake,\n",
        "                torch.zeros_like(disc_adult_down_fake)\n",
        "            )\n",
        "            \n",
        "            \n",
        "            disc_adult_down_loss = disc_adult_down_real_loss + disc_adult_down_fake_loss\"\"\"\n",
        "            disc_adult_down_loss = torch.mean(disc_adult_down_real) - torch.mean(disc_adult_down_fake) \n",
        "            writer.add_scalar(\"DisLoss\", disc_adult_down_loss,  i)\n",
        "\n",
        "            \n",
        "            \n",
        "            \n",
        "            #Como no hay consistencia de ciclo no neecesitamos entrenar los segundos generadores \n",
        "            #Lo juntamos todo, no nos sirve para entreno solo para ver como va la cosa\n",
        "            D_loss = disc_adult_down_loss\n",
        "            \n",
        "            #adults_reals += disc_adult_down_real.mean().item()\n",
        "            #adults_fakes += disc_adult_down_fake.mean().item()\n",
        "        \n",
        "        \n",
        "        #APLICAMOS LOS CAMBIOS DEL ENTRENO:\n",
        "        \n",
        "        #DOWN\n",
        "        opt_disc_Adults_down.zero_grad()\n",
        "        d_down_scaler.scale(D_loss).backward()\n",
        "        d_down_scaler.step(opt_disc_Adults_down)\n",
        "        d_down_scaler.update()\n",
        "        \n",
        "        \n",
        "        #Ahora entrenamos los generadores con lo que hemos sacado de los discriminadores\n",
        "        with torch.cuda.amp.autocast():\n",
        "            generated_images = down_sampler(kid)\n",
        "            #adversarial loss para los generadores\n",
        "            dis_adult_down_fake = disc_Adults_down(generated_images)\n",
        "            #loss_gen_down_adult = mse(dis_adult_down_fake, torch.ones_like(dis_adult_down_fake))\n",
        "            loss_gen_down_adult = torch.mean(dis_adult_down_fake)\n",
        "            writer.add_scalar(\"GenLoss\", loss_gen_down_adult, i)\n",
        "\n",
        "            \n",
        "            #identity loss (para no alterar las caracteristicas principales)\n",
        "            identity_adult_down = down_sampler(adult)\n",
        "            identity_adult_down_loss = l1(adult_frontier, identity_adult_down)\n",
        "            writer.add_scalar(\"IdentityLoss\", identity_adult_down_loss, i)\n",
        "            \n",
        "            #Se suma todo\n",
        "            g_down_loss = (loss_gen_down_adult + identity_adult_down_loss*LAMBDA_IDENTITY)\n",
        "            \n",
        "        #APLICAMOS LOS CAMBIOS DEL ENTRENO:\n",
        "        \n",
        "        #DOWN\n",
        "        opt_gen_down.zero_grad()\n",
        "        g_down_scaler.scale(g_down_loss).backward()\n",
        "        g_down_scaler.step(opt_gen_down)\n",
        "        g_down_scaler.update()\n",
        "\n",
        "        \n",
        "        if idx%500==0:\n",
        "            save_image(generated_images*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/output{idx}.png\")\n",
        "            save_image(kid*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/input{idx}.png\")\n",
        "            save_image(adult_frontier*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/target{idx}.png\")\n",
        "            save_checkpoint(down_sampler, opt_gen_down, filename=\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/gen_down.pth.tar\")\n",
        "            save_checkpoint(disc_Kids_down, opt_disc_Adults_down, filename=\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/disc_Kids_down.pth.tar\")\n",
        "            save_checkpoint(disc_Adults_down, opt_disc_Kids_down, filename=\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/disc_Adults_down.pth.tar\")\n",
        "\n",
        "            \n",
        "            img_grid = torchvision.utils.make_grid(adult)\n",
        "            #matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "            writer.add_image('input_down', torchvision.utils.make_grid(kid), i)\n",
        "\n",
        "            writer.add_image('output_down', torchvision.utils.make_grid(fake_adult_down), i)\n",
        "\n",
        "            writer.add_image('target', torchvision.utils.make_grid(adult_frontier), i)\n",
        "            #writer.add_image('fake_adults_down', torchvision.utils.make_grid(fake_adult_down),idx)\n",
        "            #writer.add_image('fake_adults_res', torchvision.utils.make_grid(fake_adult_res), idx)\n",
        "            #writer.add_graph(down_sampler,kid)\n",
        "        \n",
        "        loop.set_postfix(GenLoss = torch.mean(g_down_loss), DisLoss = torch.mean(D_loss))\n",
        "            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28P89XypfRk8",
        "outputId": "289f3f9f-62df-43f9-fe88-ce056bb433a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5, 0.5, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "[0.5 for _ in range(3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "09f6cd14",
        "outputId": "78ca3abf-296c-4b63-b227-7a7bdb2a8c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generador_down(\n",
            "  (model_sequential): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ResidualBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (7): ResidualBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (8): Identity()\n",
            "    (9): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Identity()\n",
            "    (12): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Identity()\n",
            "    (15): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): Tanh()\n",
            "  )\n",
            ")\n",
            "torch.Size([1, 3, 64, 64])\n",
            "Currently in epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/658 [00:00<?, ?it/s]\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Could not convert image_data into an image; ignored\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Could not convert image_data into an image; ignored\n",
            "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Could not convert image_data into an image; ignored\n",
            "  2%|▏         | 12/658 [00:02<02:21,  4.58it/s, DisLoss=tensor(-0.0610, device='cuda:0', dtype=torch.float16, grad_fn=<MeanBackward0>), GenLoss=tensor(0.1230, device='cuda:0', grad_fn=<MeanBackward0>)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-07103c547463>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-07103c547463>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Currently in epoch: {epoch+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         train_individual_down(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-852b1b983a8b>\u001b[0m in \u001b[0;36mtrain_individual_down\u001b[0;34m(writer, epoch, i, loader, l1, mse, disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_Adults_down, opt_disc_Kids_down, opt_gen_down, d_down_scaler, g_down_scaler)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#Ahora entrenamos los generadores con lo que hemos sacado de los discriminadores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;31m#adversarial loss para los generadores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdis_adult_down_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_Adults_down\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8976d5d2720c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;31m#print(f\"init shape{x.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m#print(f\"for layer:{layer} shape returned is: {x.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \n",
        "    \n",
        "    #Dataset\n",
        "    img_size = 128\n",
        "    frontier = 64\n",
        "    channels = 3\n",
        "    \n",
        "    dataset_full = A.Compose([\n",
        "        A.Resize(width=img_size, height=img_size),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5 for _ in range(channels)], std=[0.5 for _ in range(channels)], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],additional_targets={\"image0\": \"image\"},)\n",
        "\n",
        "    dataset_frontier = A.Compose([\n",
        "            A.Resize(width=frontier, height=frontier),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Normalize(mean=[0.5 for _ in range(channels)], std=[0.5 for _ in range(channels)], max_pixel_value=255),\n",
        "            ToTensorV2(),\n",
        "        ],additional_targets={\"image0\": \"image\"},)\n",
        "    \n",
        "        \n",
        "    train_path = \".\"\n",
        "    Adults_train = os.path.join(train_path, 'Kids')\n",
        "    Kids_train = os.path.join(train_path, 'Adults')\n",
        "    \n",
        "    dataset = TFGAN_Dataset(Adults_train, Kids_train, transform1=dataset_full, transform2=dataset_frontier,gray_scale=False)\n",
        "    loader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,pin_memory=True,)\n",
        "    \n",
        "    #Loss functions\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "    \n",
        "    #DOWN\n",
        "    \"\"\"disc_Adults_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "    disc_Kids_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "    down_sampler = Generador_down(img_size,init_channels=channels,frontier=frontier, paso_de_canal=5, rabit_hole=3, num_residuals=2).to(DEVICE)\n",
        "    opt_disc_Adults_down = optim.Adam(disc_Adults_down.parameters(),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_disc_Kids_down = optim.Adam(disc_Kids_down.parameters(),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_gen_down = optim.Adam(down_sampler.parameters(),\n",
        "                              lr=LEARNING_RATE_GEN,betas=(0.5, 0.999),)\n",
        "    d_down_scaler = torch.cuda.amp.GradScaler()\n",
        "    g_down_scaler = torch.cuda.amp.GradScaler()\"\"\"\n",
        "\n",
        "    disc_Adults_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "    disc_Kids_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "    down_sampler = Generador_down(img_size,init_channels=channels,frontier=frontier, paso_de_canal=5, rabit_hole=3, num_residuals=2).to(DEVICE)\n",
        "    opt_disc_Adults_down = optim.Adam(disc_Adults_down.parameters(),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_disc_Kids_down = optim.Adam(disc_Kids_down.parameters(),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_gen_down = optim.Adam(down_sampler.parameters(),\n",
        "                              lr=LEARNING_RATE_GEN,betas=(0.5, 0.999),)\n",
        "    d_down_scaler = torch.cuda.amp.GradScaler()\n",
        "    g_down_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    #carga\n",
        "    \"\"\"load_checkpoint(\"/content/drive/MyDrive/TFG/Images/Entrenamiento9/dis_Adults.tar\", disc_Adults_down, opt_disc_Adults_down, LEARNING_RATE_DIS)\n",
        "    load_checkpoint(\"/content/drive/MyDrive/TFG/Images/Entrenamiento9/disc_Kids.pth.tar\", disc_Kids_down, opt_disc_Kids_down, LEARNING_RATE_DIS)\n",
        "    load_checkpoint(\"/content/drive/MyDrive/TFG/Images/Entrenamiento9/gen_down.pth.tar\", down_sampler, opt_gen_down, LEARNING_RATE_GEN)\"\"\"\n",
        "\n",
        "\n",
        "    \n",
        "    #RES\n",
        "    disc_Adults_res = Discriminador(frontier,channels=channels, frontier=8).to(DEVICE)\n",
        "    disc_Kids_res = Discriminador(frontier,channels=channels, frontier=8).to(DEVICE)\n",
        "    res_sampler = Generador_res(frontier,4,num_de_paso=3,init_channels=channels,paso_de_canal=5,num_residuals=4).to(DEVICE)\n",
        "    opt_disc_res = optim.Adam(list(disc_Adults_res.parameters()) + list(disc_Kids_res.parameters()),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_gen_res = optim.Adam(list(res_sampler.parameters()),\n",
        "                              lr=LEARNING_RATE_GEN,betas=(0.5, 0.999),)\n",
        "    d_res_scaler = torch.cuda.amp.GradScaler()\n",
        "    g_res_scaler = torch.cuda.amp.GradScaler()\n",
        "    \n",
        "    \n",
        "    #UP\n",
        "    disc_Adults_up = Discriminador(img_size,channels=channels,frontier=8).to(DEVICE)\n",
        "    disc_Kids_up = Discriminador(img_size,channels=channels,frontier=8).to(DEVICE)\n",
        "    up_sampler = UpSampler(img_size, channels=channels,frontier=frontier).to(DEVICE)\n",
        "    opt_disc_up = optim.Adam(list(disc_Adults_up.parameters()) + list(disc_Kids_up.parameters()),\n",
        "                               lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "    opt_gen_up = optim.Adam(list(up_sampler.parameters()),\n",
        "                              lr=LEARNING_RATE_GEN,betas=(0.5, 0.999),)\n",
        "    d_up_scaler = torch.cuda.amp.GradScaler()\n",
        "    g_up_scaler = torch.cuda.amp.GradScaler()\n",
        "    \n",
        "    #debug\n",
        "    print(down_sampler)\n",
        "    x = torch.randn((1,channels,img_size,img_size)).to(DEVICE)\n",
        "    print(down_sampler(x).shape)\n",
        "    #TensorBoard\n",
        "    writer = SummaryWriter()\n",
        "    i = 0\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        \"\"\"train_individual(\n",
        "            writer, epoch, i,\n",
        "            loader, L1, mse,\n",
        "            disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_down, opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "            disc_Adults_res, disc_Kids_res, res_sampler, opt_disc_res, opt_gen_res, d_res_scaler, g_res_scaler,\n",
        "            disc_Adults_up, disc_Kids_up, up_sampler, opt_disc_up, opt_gen_up, d_up_scaler, g_up_scaler\n",
        "        \n",
        "        )\"\"\"\n",
        "\n",
        "        print(f\"Currently in epoch: {epoch+1}\")\n",
        "        writer.add_scalar(\"Epoch\", epoch, i)\n",
        "        train_individual_down(\n",
        "            writer, epoch, i,\n",
        "            loader, L1, mse,\n",
        "            disc_Adults_down, disc_Kids_down, down_sampler, \n",
        "            opt_disc_Adults_down, opt_disc_Kids_down, \n",
        "            opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "        )\n",
        "        i+=1\n",
        "    writer.close()\n",
        "        \n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbL0196N4quc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "8fc30a60-6107-4bbf-f2f1-2eacbe4d253b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/658 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-987b0890cac6>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m genera_down(\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-987b0890cac6>\u001b[0m in \u001b[0;36mgenera_down\u001b[0;34m(writer, epoch, i, loader, l1, mse, disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_Adults_down, opt_disc_Kids_down, opt_gen_down, d_down_scaler, g_down_scaler)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madult_frontier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkid_frontier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/TFG/Images/Resultados/output{idx}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkid\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/TFG/Images/Resultados/input{idx}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8976d5d2720c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;31m#print(f\"init shape{x.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m#print(f\"for layer:{layer} shape returned is: {x.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (float) and bias type (c10::Half) should be the same"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "#Dataset\n",
        "img_size = 128\n",
        "frontier = 64\n",
        "channels = 3\n",
        "\n",
        "dataset_full = A.Compose([\n",
        "    A.Resize(width=img_size, height=img_size),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(mean=[0.5 for _ in range(channels)], std=[0.5 for _ in range(channels)], max_pixel_value=255),\n",
        "    ToTensorV2(),\n",
        "],additional_targets={\"image0\": \"image\"},)\n",
        "\n",
        "dataset_frontier = A.Compose([\n",
        "        A.Resize(width=frontier, height=frontier),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5 for _ in range(channels)], std=[0.5 for _ in range(channels)], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],additional_targets={\"image0\": \"image\"},)\n",
        "\n",
        "    \n",
        "train_path = \".\"\n",
        "Adults_train = os.path.join(train_path, 'Kids')\n",
        "Kids_train = os.path.join(train_path, 'Adults')\n",
        "\n",
        "dataset = TFGAN_Dataset(Adults_train, Kids_train, transform1=dataset_full, transform2=dataset_frontier,gray_scale=False)\n",
        "loader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,pin_memory=True,)\n",
        "disc_Adults_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "disc_Kids_down = Discriminador(frontier,channels=channels,frontier=4).to(DEVICE)\n",
        "down_sampler = Generador_down(img_size,init_channels=channels,frontier=frontier, paso_de_canal=5, rabit_hole=3, num_residuals=2).to(DEVICE)\n",
        "opt_disc_Adults_down = optim.Adam(disc_Adults_down.parameters(),\n",
        "                            lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "opt_disc_Kids_down = optim.Adam(disc_Kids_down.parameters(),\n",
        "                            lr=LEARNING_RATE_DIS,betas=(0.5, 0.999),)\n",
        "opt_gen_down = optim.Adam(down_sampler.parameters(),\n",
        "                          lr=LEARNING_RATE_GEN,betas=(0.5, 0.999),)\n",
        "d_down_scaler = torch.cuda.amp.GradScaler()\n",
        "g_down_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "#carga\n",
        "load_checkpoint(\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/disc_Adults_down.pth.tar\", disc_Adults_down, opt_disc_Adults_down, LEARNING_RATE_DIS)\n",
        "load_checkpoint(\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/disc_Kids_down.pth.tar\", disc_Kids_down, opt_disc_Kids_down, LEARNING_RATE_DIS)\n",
        "load_checkpoint(\"/content/drive/MyDrive/TFG/Images/EntrenamientoFINAL/Modelos/gen_down.pth.tar\", down_sampler, opt_gen_down, LEARNING_RATE_GEN)\n",
        "\n",
        "def genera_down(\n",
        "    writer, epoch, i,\n",
        "    loader, l1, mse, \n",
        "    disc_Adults_down, disc_Kids_down, down_sampler, opt_disc_Adults_down, opt_disc_Kids_down, opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "):\n",
        "    \n",
        "    adults_reals = 0\n",
        "    adults_fakes = 0\n",
        "    \n",
        "    loop = tqdm(loader, leave=True)\n",
        "    \n",
        "    for idx, (adult, kid, adult_frontier, kid_frontier) in enumerate(loop):\n",
        "      with torch.cuda.amp.autocast():\n",
        "        generated_images = down_sampler(kid)\n",
        "        save_image(generated_images*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Resultados/output{idx}.png\")\n",
        "        save_image(kid*0.5+0.5,f\"/content/drive/MyDrive/TFG/Images/Resultados/input{idx}.png\")\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "genera_down(\n",
        "            None, None, 0,\n",
        "            loader, None, None,\n",
        "            disc_Adults_down.to(DEVICE), disc_Kids_down.to(DEVICE), down_sampler.to(DEVICE), \n",
        "            opt_disc_Adults_down, opt_disc_Kids_down, \n",
        "            opt_gen_down, d_down_scaler, g_down_scaler,\n",
        "        )\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vUlTGaMmtrtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
